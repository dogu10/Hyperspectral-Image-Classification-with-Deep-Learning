{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "81da4fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.layers import Conv2D, Conv3D, Flatten, Dense, Reshape, BatchNormalization\n",
    "from keras.layers import Dropout, Input \n",
    "from tensorflow.keras.models import Model\n",
    "from keras.optimizers import Adam, SGD\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.utils import np_utils\n",
    "from keras import backend as Kb\n",
    "from keras.layers import Lambda\n",
    "from keras.layers import Activation\n",
    "from keras.layers import add, concatenate\n",
    "from keras.layers import AveragePooling2D\n",
    "from keras.utils import plot_model\n",
    " \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, classification_report, cohen_kappa_score\n",
    " \n",
    "from sklearn.decomposition import FactorAnalysis\n",
    "from sklearn.decomposition import PCA\n",
    "from operator import truediv\n",
    " \n",
    "from plotly.offline import init_notebook_mode\n",
    " \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.io as sio\n",
    "from scipy.io import loadmat\n",
    "import os\n",
    "import spectral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "702566c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def applyFA(X, numComponents=75):\n",
    "    newX = np.reshape(X, (-1, X.shape[2]))\n",
    "    fa = FactorAnalysis(n_components=numComponents, random_state=0)\n",
    "    newX = fa.fit_transform(newX)\n",
    "    newX = np.reshape(newX, (X.shape[0],X.shape[1], numComponents))\n",
    "    return newX, fa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "088295f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "## GLOBAL VARIABLES\n",
    "dataset = 'SA'\n",
    "test_ratio = 0.6\n",
    "windowSize = 24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a82a637d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#def loadmat(name):\n",
    "\n",
    "X=loadmat('../hyperspectral/salinas_corrected.mat')['salinas_corrected']\n",
    "y=loadmat('../hyperspectral/salinas_gt.mat')['salinas_gt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d94a8dee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def splitTrainTestSet(X, y, testRatio, randomState=345):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=testRatio, random_state=randomState,\n",
    "                                                        stratify=y)\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "219e9d56",
   "metadata": {},
   "outputs": [],
   "source": [
    "def padWithZeros(X, margin=2):\n",
    "    newX = np.zeros((X.shape[0] + 2 * margin, X.shape[1] + 2* margin, X.shape[2]))\n",
    "    x_offset = margin\n",
    "    y_offset = margin\n",
    "    newX[x_offset:X.shape[0] + x_offset, y_offset:X.shape[1] + y_offset, :] = X\n",
    "    return newX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2e88325b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createImageCubes(X, y, windowSize=8, removeZeroLabels = True):\n",
    "    margin = int((windowSize) / 2)\n",
    "    zeroPaddedX = padWithZeros(X, margin=margin)\n",
    "    # split patches\n",
    "    patchesData = np.zeros((X.shape[0] * X.shape[1], windowSize, windowSize, X.shape[2]))\n",
    "    patchesLabels = np.zeros((X.shape[0] * X.shape[1]))\n",
    "    patchIndex = 0\n",
    "    for r in range(margin, zeroPaddedX.shape[0] - margin):\n",
    "        for c in range(margin, zeroPaddedX.shape[1] - margin):\n",
    "            patch = zeroPaddedX[r - margin:r + margin , c - margin:c + margin ]   \n",
    "            patchesData[patchIndex, :, :, :] = patch\n",
    "            patchesLabels[patchIndex] = y[r-margin, c-margin]\n",
    "            patchIndex = patchIndex + 1\n",
    "    if removeZeroLabels:\n",
    "        patchesData = patchesData[patchesLabels>0,:,:,:]\n",
    "        patchesLabels = patchesLabels[patchesLabels>0]\n",
    "        patchesLabels -= 1\n",
    "    return patchesData, patchesLabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "526b21ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((512, 217, 204), (512, 217))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "699ed20e",
   "metadata": {},
   "outputs": [],
   "source": [
    "K = X.shape[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "28f2a340",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(512, 217, 3)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K = 3 if dataset == 'SA' else 3\n",
    "X,fa = applyFA(X,numComponents=K)\n",
    "\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ee19344d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((54129, 24, 24, 3), (54129,))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = createImageCubes(X, y, windowSize=windowSize)\n",
    "\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "da920cb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((21651, 24, 24, 3), (32478, 24, 24, 3), (21651,), (32478,))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtrain, Xtest, ytrain, ytest = splitTrainTestSet(X, y, test_ratio)\n",
    "\n",
    "Xtrain.shape, Xtest.shape, ytrain.shape, ytest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "740ea2d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21651, 24, 24, 3, 1)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtrain = Xtrain.reshape(-1, windowSize, windowSize, K, 1)\n",
    "Xtrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "21e7a94c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21651, 16)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ytrain = np_utils.to_categorical(ytrain)\n",
    "ytrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7944ec8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "S1 = windowSize\n",
    "L1 = K\n",
    "output_units = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bcf14206",
   "metadata": {},
   "outputs": [],
   "source": [
    "def WaveletTransformAxisY(batch_img):\n",
    "    odd_img  = batch_img[:,0::2]\n",
    "    even_img = batch_img[:,1::2]\n",
    "    L = (odd_img + even_img) / 2.0\n",
    "    H = Kb.abs(odd_img - even_img)\n",
    "    return L, H\n",
    "\n",
    "def WaveletTransformAxisX(batch_img):\n",
    "    # transpose + fliplr\n",
    "    tmp_batch = Kb.permute_dimensions(batch_img, [0, 2, 1])[:,:,::-1]\n",
    "    _dst_L, _dst_H = WaveletTransformAxisY(tmp_batch)\n",
    "    # transpose + flipud\n",
    "    dst_L = Kb.permute_dimensions(_dst_L, [0, 2, 1])[:,::-1,...]\n",
    "    dst_H = Kb.permute_dimensions(_dst_H, [0, 2, 1])[:,::-1,...]\n",
    "    return dst_L, dst_H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d62afe35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Wavelet(batch_image):\n",
    "    # make channel first image\n",
    "    batch_image = Kb.permute_dimensions(batch_image, [0, 3, 1, 2])\n",
    "    r = batch_image[:,0]\n",
    "    g = batch_image[:,1]\n",
    "    b = batch_image[:,2]\n",
    "\n",
    "    # level 1 decomposition\n",
    "    wavelet_L, wavelet_H = WaveletTransformAxisY(r)\n",
    "    r_wavelet_LL, r_wavelet_LH = WaveletTransformAxisX(wavelet_L)\n",
    "    r_wavelet_HL, r_wavelet_HH = WaveletTransformAxisX(wavelet_H)\n",
    "\n",
    "    wavelet_L, wavelet_H = WaveletTransformAxisY(g)\n",
    "    g_wavelet_LL, g_wavelet_LH = WaveletTransformAxisX(wavelet_L)\n",
    "    g_wavelet_HL, g_wavelet_HH = WaveletTransformAxisX(wavelet_H)\n",
    "\n",
    "    wavelet_L, wavelet_H = WaveletTransformAxisY(b)\n",
    "    b_wavelet_LL, b_wavelet_LH = WaveletTransformAxisX(wavelet_L)\n",
    "    b_wavelet_HL, b_wavelet_HH = WaveletTransformAxisX(wavelet_H)\n",
    "\n",
    "    wavelet_data = [r_wavelet_LL, r_wavelet_LH, r_wavelet_HL, r_wavelet_HH, \n",
    "                    g_wavelet_LL, g_wavelet_LH, g_wavelet_HL, g_wavelet_HH,\n",
    "                    b_wavelet_LL, b_wavelet_LH, b_wavelet_HL, b_wavelet_HH]\n",
    "    transform_batch = Kb.stack(wavelet_data, axis=1)\n",
    "\n",
    "    # level 2 decomposition\n",
    "    wavelet_L2, wavelet_H2 = WaveletTransformAxisY(r_wavelet_LL)\n",
    "    r_wavelet_LL2, r_wavelet_LH2 = WaveletTransformAxisX(wavelet_L2)\n",
    "    r_wavelet_HL2, r_wavelet_HH2 = WaveletTransformAxisX(wavelet_H2)\n",
    "\n",
    "    wavelet_L2, wavelet_H2 = WaveletTransformAxisY(g_wavelet_LL)\n",
    "    g_wavelet_LL2, g_wavelet_LH2 = WaveletTransformAxisX(wavelet_L2)\n",
    "    g_wavelet_HL2, g_wavelet_HH2 = WaveletTransformAxisX(wavelet_H2)\n",
    "\n",
    "    wavelet_L2, wavelet_H2 = WaveletTransformAxisY(b_wavelet_LL)\n",
    "    b_wavelet_LL2, b_wavelet_LH2 = WaveletTransformAxisX(wavelet_L2)\n",
    "    b_wavelet_HL2, b_wavelet_HH2 = WaveletTransformAxisX(wavelet_H2)\n",
    "\n",
    "\n",
    "    wavelet_data_l2 = [r_wavelet_LL2, r_wavelet_LH2, r_wavelet_HL2, r_wavelet_HH2, \n",
    "                    g_wavelet_LL2, g_wavelet_LH2, g_wavelet_HL2, g_wavelet_HH2,\n",
    "                    b_wavelet_LL2, b_wavelet_LH2, b_wavelet_HL2, b_wavelet_HH2]\n",
    "    transform_batch_l2 = Kb.stack(wavelet_data_l2, axis=1)\n",
    "\n",
    "    # level 3 decomposition\n",
    "    wavelet_L3, wavelet_H3 = WaveletTransformAxisY(r_wavelet_LL2)\n",
    "    r_wavelet_LL3, r_wavelet_LH3 = WaveletTransformAxisX(wavelet_L3)\n",
    "    r_wavelet_HL3, r_wavelet_HH3 = WaveletTransformAxisX(wavelet_H3)\n",
    "\n",
    "    wavelet_L3, wavelet_H3 = WaveletTransformAxisY(g_wavelet_LL2)\n",
    "    g_wavelet_LL3, g_wavelet_LH3 = WaveletTransformAxisX(wavelet_L3)\n",
    "    g_wavelet_HL3, g_wavelet_HH3 = WaveletTransformAxisX(wavelet_H3)\n",
    "\n",
    "    wavelet_L3, wavelet_H3 = WaveletTransformAxisY(b_wavelet_LL2)\n",
    "    b_wavelet_LL3, b_wavelet_LH3 = WaveletTransformAxisX(wavelet_L3)\n",
    "    b_wavelet_HL3, b_wavelet_HH3 = WaveletTransformAxisX(wavelet_H3)\n",
    "\n",
    "    wavelet_data_l3 = [r_wavelet_LL3, r_wavelet_LH3, r_wavelet_HL3, r_wavelet_HH3, \n",
    "                    g_wavelet_LL3, g_wavelet_LH3, g_wavelet_HL3, g_wavelet_HH3,\n",
    "                    b_wavelet_LL3, b_wavelet_LH3, b_wavelet_HL3, b_wavelet_HH3]\n",
    "    transform_batch_l3 = Kb.stack(wavelet_data_l3, axis=1)\n",
    "\n",
    "    # level 4 decomposition\n",
    "    wavelet_L4, wavelet_H4 = WaveletTransformAxisY(r_wavelet_LL3)\n",
    "    r_wavelet_LL4, r_wavelet_LH4 = WaveletTransformAxisX(wavelet_L4)\n",
    "    r_wavelet_HL4, r_wavelet_HH4 = WaveletTransformAxisX(wavelet_H4)\n",
    "\n",
    "    wavelet_L4, wavelet_H4 = WaveletTransformAxisY(g_wavelet_LL3)\n",
    "    g_wavelet_LL4, g_wavelet_LH4 = WaveletTransformAxisX(wavelet_L4)\n",
    "    g_wavelet_HL4, g_wavelet_HH4 = WaveletTransformAxisX(wavelet_H4)\n",
    "\n",
    "    wavelet_L3, wavelet_H3 = WaveletTransformAxisY(b_wavelet_LL3)\n",
    "    b_wavelet_LL4, b_wavelet_LH4 = WaveletTransformAxisX(wavelet_L4)\n",
    "    b_wavelet_HL4, b_wavelet_HH4 = WaveletTransformAxisX(wavelet_H4)\n",
    "\n",
    "\n",
    "    wavelet_data_l4 = [r_wavelet_LL4, r_wavelet_LH4, r_wavelet_HL4, r_wavelet_HH4, \n",
    "                    g_wavelet_LL4, g_wavelet_LH4, g_wavelet_HL4, g_wavelet_HH4,\n",
    "                    b_wavelet_LL4, b_wavelet_LH4, b_wavelet_HL4, b_wavelet_HH4]\n",
    "    transform_batch_l4 = Kb.stack(wavelet_data_l4, axis=1)\n",
    "\n",
    "    # print('shape before')\n",
    "    # print(transform_batch.shape)\n",
    "    # print(transform_batch_l2.shape)\n",
    "    # print(transform_batch_l3.shape)\n",
    "    # print(transform_batch_l4.shape)\n",
    "\n",
    "    decom_level_1 = Kb.permute_dimensions(transform_batch, [0, 2, 3, 1])\n",
    "    decom_level_2 = Kb.permute_dimensions(transform_batch_l2, [0, 2, 3, 1])\n",
    "    decom_level_3 = Kb.permute_dimensions(transform_batch_l3, [0, 2, 3, 1])\n",
    "    decom_level_4 = Kb.permute_dimensions(transform_batch_l4, [0, 2, 3, 1])\n",
    "    \n",
    "    # print('shape after')\n",
    "    # print(decom_level_1.shape)\n",
    "    # print(decom_level_2.shape)\n",
    "    # print(decom_level_3.shape)\n",
    "    # print(decom_level_4.shape)\n",
    "    return [decom_level_1, decom_level_2, decom_level_3, decom_level_4]\n",
    "\n",
    "\n",
    "def Wavelet_out_shape(input_shapes):\n",
    "    # print('in to shape')\n",
    "    return [tuple([None, 112, 112, 12]), tuple([None, 56, 56, 12]), \n",
    "            tuple([None, 28, 28, 12]), tuple([None, 14, 14, 12])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9bf23b09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor: shape=(8, 12, 12, 12), dtype=float32, numpy=\n",
       " array([[[[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]]],\n",
       " \n",
       " \n",
       "        [[[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]]],\n",
       " \n",
       " \n",
       "        [[[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]]],\n",
       " \n",
       " \n",
       "        ...,\n",
       " \n",
       " \n",
       "        [[[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]]],\n",
       " \n",
       " \n",
       "        [[[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]]],\n",
       " \n",
       " \n",
       "        [[[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         ...,\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          ...,\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]]]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(8, 6, 6, 12), dtype=float32, numpy=\n",
       " array([[[[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]]],\n",
       " \n",
       " \n",
       "        [[[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]]],\n",
       " \n",
       " \n",
       "        [[[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]]],\n",
       " \n",
       " \n",
       "        ...,\n",
       " \n",
       " \n",
       "        [[[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]]],\n",
       " \n",
       " \n",
       "        [[[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]]],\n",
       " \n",
       " \n",
       "        [[[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.],\n",
       "          [0., 0., 0., ..., 0., 0., 0.]]]], dtype=float32)>,\n",
       " <tf.Tensor: shape=(8, 3, 3, 12), dtype=float32, numpy=\n",
       " array([[[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]],\n",
       " \n",
       " \n",
       "        [[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]],\n",
       " \n",
       " \n",
       "        [[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]],\n",
       " \n",
       " \n",
       "        [[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]],\n",
       " \n",
       " \n",
       "        [[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]],\n",
       " \n",
       " \n",
       "        [[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]],\n",
       " \n",
       " \n",
       "        [[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]],\n",
       " \n",
       " \n",
       "        [[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]]],\n",
       "       dtype=float32)>,\n",
       " <tf.Tensor: shape=(8, 2, 2, 12), dtype=float32, numpy=\n",
       " array([[[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]],\n",
       " \n",
       " \n",
       "        [[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]],\n",
       " \n",
       " \n",
       "        [[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]],\n",
       " \n",
       " \n",
       "        [[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]],\n",
       " \n",
       " \n",
       "        [[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]],\n",
       " \n",
       " \n",
       "        [[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]],\n",
       " \n",
       " \n",
       "        [[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]],\n",
       " \n",
       " \n",
       "        [[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       " \n",
       "         [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]]],\n",
       "       dtype=float32)>]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_batch = Kb.zeros(shape=(8, 24, 24, 3), dtype='float32')\n",
    "Wavelet(img_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee52b613",
   "metadata": {},
   "source": [
    "# 2D CNN YÖNTEMİ\n",
    "\n",
    "Veri kaybını önlemek için *same padding* metodu kullanılıyor.\n",
    "Eksi değerlerin sıfırlanması için *relu* uygulanır.\n",
    "Parametre sayısını azaltmak için *max pooling* işlemi uygulanır.\n",
    "conv.ve pooling işlemi sonrası x satır 1 sütundan oluşan vektöre dönüştürmek için *flattening* işlemi uygulanır.\n",
    "*Dense Layer*  bir katmandan aldığı nöronları bir sonraki katmana girdi olarak bağlanmasını sağlar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f43c7cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wavelet_cnn_model():\n",
    " \n",
    "    input_shape =  24, 24, 3\n",
    " \n",
    "    input_ = Input(input_shape, name='the_input')\n",
    "    # wavelet = Lambda(Wavelet, name='wavelet')\n",
    "    wavelet = Lambda(Wavelet, Wavelet_out_shape, name='wavelet')\n",
    "    input_l1, input_l2, input_l3, input_l4 = wavelet(input_)\n",
    "  \n",
    "    # level one decomposition starts\n",
    "    conv_1 = Conv2D(64, kernel_size=(3, 3), padding='same', name='conv_1')(input_l1)\n",
    "    norm_1 = BatchNormalization(name='norm_1')(conv_1)\n",
    "    relu_1 = Activation('relu', name='relu_1')(norm_1)\n",
    " \n",
    "    conv_1_2 = Conv2D(64, kernel_size=(3, 3), strides=(2, 2), padding='same', name='conv_1_2')(relu_1)\n",
    "    norm_1_2 = BatchNormalization(name='norm_1_2')(conv_1_2)\n",
    "    relu_1_2 = Activation('relu', name='relu_1_2')(norm_1_2)\n",
    " \n",
    "    # level two decomposition starts\n",
    "    conv_a = Conv2D(filters=64, kernel_size=(3, 3), padding='same', name='conv_a')(input_l2)\n",
    "    norm_a = BatchNormalization(name='norm_a')(conv_a)\n",
    "    relu_a = Activation('relu', name='relu_a')(norm_a)\n",
    " \n",
    "    # concate level one and level two decomposition\n",
    "    concate_level_2 = concatenate([relu_1_2, relu_a])\n",
    "    conv_2 = Conv2D(128, kernel_size=(3, 3), padding='same', name='conv_2')(concate_level_2)\n",
    "    norm_2 = BatchNormalization(name='norm_2')(conv_2)\n",
    "    relu_2 = Activation('relu', name='relu_2')(norm_2)\n",
    " \n",
    "    conv_2_2 = Conv2D(128, kernel_size=(3, 3), strides=(2, 2), padding='same', name='conv_2_2')(relu_2)\n",
    "    norm_2_2 = BatchNormalization(name='norm_2_2')(conv_2_2)\n",
    "    relu_2_2 = Activation('relu', name='relu_2_2')(norm_2_2)\n",
    " \n",
    "    # level three decomposition starts \n",
    "    conv_b = Conv2D(filters=64, kernel_size=(3, 3), padding='same', name='conv_b')(input_l3)\n",
    "    norm_b = BatchNormalization(name='norm_b')(conv_b)\n",
    "    relu_b = Activation('relu', name='relu_b')(norm_b)\n",
    " \n",
    "    conv_b_2 = Conv2D(128, kernel_size=(3, 3), padding='same', name='conv_b_2')(relu_b)\n",
    "    norm_b_2 = BatchNormalization(name='norm_b_2')(conv_b_2)\n",
    "    relu_b_2 = Activation('relu', name='relu_b_2')(norm_b_2)\n",
    " \n",
    "    # concate level two and level three decomposition \n",
    "    concate_level_3 = concatenate([relu_2_2, relu_b_2])\n",
    "    conv_3 = Conv2D(256, kernel_size=(3, 3), padding='same', name='conv_3')(concate_level_3)\n",
    "    norm_3 = BatchNormalization(name='nomr_3')(conv_3)\n",
    "    relu_3 = Activation('relu', name='relu_3')(norm_3)\n",
    " \n",
    "    conv_3_2 = Conv2D(256, kernel_size=(3, 3), strides=(2, 2), padding='same', name='conv_3_2')(relu_3)\n",
    "    norm_3_2 = BatchNormalization(name='norm_3_2')(conv_3_2)\n",
    "    relu_3_2 = Activation('relu', name='relu_3_2')(norm_3_2)\n",
    " \n",
    "    # level four decomposition start\n",
    "    conv_c = Conv2D(64, kernel_size=(3, 3), padding='same', name='conv_c')(input_l4)\n",
    "    norm_c = BatchNormalization(name='norm_c')(conv_c)\n",
    "    relu_c = Activation('relu', name='relu_c')(norm_c)\n",
    " \n",
    "    conv_c_2 = Conv2D(256, kernel_size=(3, 3), padding='same', name='conv_c_2')(relu_c)\n",
    "    norm_c_2 = BatchNormalization(name='norm_c_2')(conv_c_2)\n",
    "    relu_c_2 = Activation('relu', name='relu_c_2')(norm_c_2)\n",
    " \n",
    "    conv_c_3 = Conv2D(256, kernel_size=(3, 3), padding='same', name='conv_c_3')(relu_c_2)\n",
    "    norm_c_3 = BatchNormalization(name='norm_c_3')(conv_c_3)\n",
    "    relu_c_3 = Activation('relu', name='relu_c_3')(norm_c_3)\n",
    " \n",
    "    # concate level level three and level four decomposition\n",
    "    concate_level_4 = concatenate([relu_3_2, relu_c_3])\n",
    "    conv_4 = Conv2D(256, kernel_size=(3, 3), padding='same', name='conv_4')(concate_level_4)\n",
    "    norm_4 = BatchNormalization(name='norm_4')(conv_4)\n",
    "    relu_4 = Activation('relu', name='relu_4')(norm_4)\n",
    " \n",
    "    conv_4_2 = Conv2D(256, kernel_size=(3, 3), strides=(2, 2), padding='same', name='conv_4_2')(relu_4)\n",
    "    norm_4_2 = BatchNormalization(name='norm_4_2')(conv_4_2)\n",
    "    relu_4_2 = Activation('relu', name='relu_4_2')(norm_4_2)\n",
    " \n",
    "    conv_5_1 = Conv2D(128, kernel_size=(3, 3), padding='same', name='conv_5_1')(relu_4_2)\n",
    "    norm_5_1 = BatchNormalization(name='norm_5_1')(conv_5_1)\n",
    "    relu_5_1 = Activation('relu', name='relu_5_1')(norm_5_1)\n",
    " \n",
    "    pool_5_1 = AveragePooling2D(pool_size=(7, 7), strides=1, padding='same', name='avg_pool_5_1')(relu_5_1)\n",
    "    \n",
    "    flatten_layer = Flatten()(pool_5_1)\n",
    " \n",
    "    dense_layer1 = Dense(units=2048, activation='relu')(flatten_layer)\n",
    "    dense_layer1 = Dropout(0.4)(dense_layer1)\n",
    "    dense_layer2 = Dense(units=1024, activation='relu')(dense_layer1)\n",
    "    dense_layer2 = Dropout(0.4)(dense_layer2)\n",
    "    output_layer = Dense(units=output_units, activation='softmax')(dense_layer2)\n",
    " \n",
    "    model = Model(inputs=input_, outputs=output_layer)\n",
    "    model.summary()\n",
    "    plot_model(model, to_file='wavelet_cnn_0.5.png')\n",
    " \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1e9251e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " the_input (InputLayer)         [(None, 24, 24, 3)]  0           []                               \n",
      "                                                                                                  \n",
      " wavelet (Lambda)               [(None, 12, 12, 12)  0           ['the_input[0][0]']              \n",
      "                                , (None, 6, 6, 12),                                               \n",
      "                                 (None, 3, 3, 12),                                                \n",
      "                                 (None, 2, 2, 12)]                                                \n",
      "                                                                                                  \n",
      " conv_1 (Conv2D)                (None, 12, 12, 64)   6976        ['wavelet[0][0]']                \n",
      "                                                                                                  \n",
      " norm_1 (BatchNormalization)    (None, 12, 12, 64)   256         ['conv_1[0][0]']                 \n",
      "                                                                                                  \n",
      " relu_1 (Activation)            (None, 12, 12, 64)   0           ['norm_1[0][0]']                 \n",
      "                                                                                                  \n",
      " conv_1_2 (Conv2D)              (None, 6, 6, 64)     36928       ['relu_1[0][0]']                 \n",
      "                                                                                                  \n",
      " conv_a (Conv2D)                (None, 6, 6, 64)     6976        ['wavelet[0][1]']                \n",
      "                                                                                                  \n",
      " norm_1_2 (BatchNormalization)  (None, 6, 6, 64)     256         ['conv_1_2[0][0]']               \n",
      "                                                                                                  \n",
      " norm_a (BatchNormalization)    (None, 6, 6, 64)     256         ['conv_a[0][0]']                 \n",
      "                                                                                                  \n",
      " relu_1_2 (Activation)          (None, 6, 6, 64)     0           ['norm_1_2[0][0]']               \n",
      "                                                                                                  \n",
      " relu_a (Activation)            (None, 6, 6, 64)     0           ['norm_a[0][0]']                 \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 6, 6, 128)    0           ['relu_1_2[0][0]',               \n",
      "                                                                  'relu_a[0][0]']                 \n",
      "                                                                                                  \n",
      " conv_2 (Conv2D)                (None, 6, 6, 128)    147584      ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " conv_b (Conv2D)                (None, 3, 3, 64)     6976        ['wavelet[0][2]']                \n",
      "                                                                                                  \n",
      " norm_2 (BatchNormalization)    (None, 6, 6, 128)    512         ['conv_2[0][0]']                 \n",
      "                                                                                                  \n",
      " norm_b (BatchNormalization)    (None, 3, 3, 64)     256         ['conv_b[0][0]']                 \n",
      "                                                                                                  \n",
      " relu_2 (Activation)            (None, 6, 6, 128)    0           ['norm_2[0][0]']                 \n",
      "                                                                                                  \n",
      " relu_b (Activation)            (None, 3, 3, 64)     0           ['norm_b[0][0]']                 \n",
      "                                                                                                  \n",
      " conv_2_2 (Conv2D)              (None, 3, 3, 128)    147584      ['relu_2[0][0]']                 \n",
      "                                                                                                  \n",
      " conv_b_2 (Conv2D)              (None, 3, 3, 128)    73856       ['relu_b[0][0]']                 \n",
      "                                                                                                  \n",
      " norm_2_2 (BatchNormalization)  (None, 3, 3, 128)    512         ['conv_2_2[0][0]']               \n",
      "                                                                                                  \n",
      " norm_b_2 (BatchNormalization)  (None, 3, 3, 128)    512         ['conv_b_2[0][0]']               \n",
      "                                                                                                  \n",
      " conv_c (Conv2D)                (None, 2, 2, 64)     6976        ['wavelet[0][3]']                \n",
      "                                                                                                  \n",
      " relu_2_2 (Activation)          (None, 3, 3, 128)    0           ['norm_2_2[0][0]']               \n",
      "                                                                                                  \n",
      " relu_b_2 (Activation)          (None, 3, 3, 128)    0           ['norm_b_2[0][0]']               \n",
      "                                                                                                  \n",
      " norm_c (BatchNormalization)    (None, 2, 2, 64)     256         ['conv_c[0][0]']                 \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 3, 3, 256)    0           ['relu_2_2[0][0]',               \n",
      "                                                                  'relu_b_2[0][0]']               \n",
      "                                                                                                  \n",
      " relu_c (Activation)            (None, 2, 2, 64)     0           ['norm_c[0][0]']                 \n",
      "                                                                                                  \n",
      " conv_3 (Conv2D)                (None, 3, 3, 256)    590080      ['concatenate_1[0][0]']          \n",
      "                                                                                                  \n",
      " conv_c_2 (Conv2D)              (None, 2, 2, 256)    147712      ['relu_c[0][0]']                 \n",
      "                                                                                                  \n",
      " nomr_3 (BatchNormalization)    (None, 3, 3, 256)    1024        ['conv_3[0][0]']                 \n",
      "                                                                                                  \n",
      " norm_c_2 (BatchNormalization)  (None, 2, 2, 256)    1024        ['conv_c_2[0][0]']               \n",
      "                                                                                                  \n",
      " relu_3 (Activation)            (None, 3, 3, 256)    0           ['nomr_3[0][0]']                 \n",
      "                                                                                                  \n",
      " relu_c_2 (Activation)          (None, 2, 2, 256)    0           ['norm_c_2[0][0]']               \n",
      "                                                                                                  \n",
      " conv_3_2 (Conv2D)              (None, 2, 2, 256)    590080      ['relu_3[0][0]']                 \n",
      "                                                                                                  \n",
      " conv_c_3 (Conv2D)              (None, 2, 2, 256)    590080      ['relu_c_2[0][0]']               \n",
      "                                                                                                  \n",
      " norm_3_2 (BatchNormalization)  (None, 2, 2, 256)    1024        ['conv_3_2[0][0]']               \n",
      "                                                                                                  \n",
      " norm_c_3 (BatchNormalization)  (None, 2, 2, 256)    1024        ['conv_c_3[0][0]']               \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                  \n",
      " relu_3_2 (Activation)          (None, 2, 2, 256)    0           ['norm_3_2[0][0]']               \n",
      "                                                                                                  \n",
      " relu_c_3 (Activation)          (None, 2, 2, 256)    0           ['norm_c_3[0][0]']               \n",
      "                                                                                                  \n",
      " concatenate_2 (Concatenate)    (None, 2, 2, 512)    0           ['relu_3_2[0][0]',               \n",
      "                                                                  'relu_c_3[0][0]']               \n",
      "                                                                                                  \n",
      " conv_4 (Conv2D)                (None, 2, 2, 256)    1179904     ['concatenate_2[0][0]']          \n",
      "                                                                                                  \n",
      " norm_4 (BatchNormalization)    (None, 2, 2, 256)    1024        ['conv_4[0][0]']                 \n",
      "                                                                                                  \n",
      " relu_4 (Activation)            (None, 2, 2, 256)    0           ['norm_4[0][0]']                 \n",
      "                                                                                                  \n",
      " conv_4_2 (Conv2D)              (None, 1, 1, 256)    590080      ['relu_4[0][0]']                 \n",
      "                                                                                                  \n",
      " norm_4_2 (BatchNormalization)  (None, 1, 1, 256)    1024        ['conv_4_2[0][0]']               \n",
      "                                                                                                  \n",
      " relu_4_2 (Activation)          (None, 1, 1, 256)    0           ['norm_4_2[0][0]']               \n",
      "                                                                                                  \n",
      " conv_5_1 (Conv2D)              (None, 1, 1, 128)    295040      ['relu_4_2[0][0]']               \n",
      "                                                                                                  \n",
      " norm_5_1 (BatchNormalization)  (None, 1, 1, 128)    512         ['conv_5_1[0][0]']               \n",
      "                                                                                                  \n",
      " relu_5_1 (Activation)          (None, 1, 1, 128)    0           ['norm_5_1[0][0]']               \n",
      "                                                                                                  \n",
      " avg_pool_5_1 (AveragePooling2D  (None, 1, 1, 128)   0           ['relu_5_1[0][0]']               \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " flatten (Flatten)              (None, 128)          0           ['avg_pool_5_1[0][0]']           \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 2048)         264192      ['flatten[0][0]']                \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 2048)         0           ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 1024)         2098176     ['dropout[0][0]']                \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 1024)         0           ['dense_1[0][0]']                \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 16)           16400       ['dropout_1[0][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 6,805,072\n",
      "Trainable params: 6,800,336\n",
      "Non-trainable params: 4,736\n",
      "__________________________________________________________________________________________________\n",
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n"
     ]
    }
   ],
   "source": [
    "model = get_wavelet_cnn_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "95977931",
   "metadata": {},
   "outputs": [],
   "source": [
    "#adam = Adam(lr=0.001, decay=1e-06)\n",
    "sgd = SGD(learning_rate=0.01, momentum=0.9, nesterov=False)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ce907a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = \"best-model.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='acc', verbose=1, save_best_only=False, mode='max')\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1df33aea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "722/722 [==============================] - ETA: 0s - loss: 0.2519 - accuracy: 0.9203\n",
      "Epoch 1: saving model to best-model.hdf5\n",
      "722/722 [==============================] - 136s 181ms/step - loss: 0.2519 - accuracy: 0.9203\n",
      "Epoch 2/20\n",
      "722/722 [==============================] - ETA: 0s - loss: 0.0582 - accuracy: 0.9823\n",
      "Epoch 2: saving model to best-model.hdf5\n",
      "722/722 [==============================] - 131s 181ms/step - loss: 0.0582 - accuracy: 0.9823\n",
      "Epoch 3/20\n",
      "722/722 [==============================] - ETA: 0s - loss: 0.0408 - accuracy: 0.9888\n",
      "Epoch 3: saving model to best-model.hdf5\n",
      "722/722 [==============================] - 124s 172ms/step - loss: 0.0408 - accuracy: 0.9888\n",
      "Epoch 4/20\n",
      "722/722 [==============================] - ETA: 0s - loss: 0.0232 - accuracy: 0.9933\n",
      "Epoch 4: saving model to best-model.hdf5\n",
      "722/722 [==============================] - 118s 163ms/step - loss: 0.0232 - accuracy: 0.9933\n",
      "Epoch 5/20\n",
      "722/722 [==============================] - ETA: 0s - loss: 0.0147 - accuracy: 0.9955\n",
      "Epoch 5: saving model to best-model.hdf5\n",
      "722/722 [==============================] - 118s 163ms/step - loss: 0.0147 - accuracy: 0.9955\n",
      "Epoch 6/20\n",
      "722/722 [==============================] - ETA: 0s - loss: 0.0137 - accuracy: 0.9959\n",
      "Epoch 6: saving model to best-model.hdf5\n",
      "722/722 [==============================] - 118s 163ms/step - loss: 0.0137 - accuracy: 0.9959\n",
      "Epoch 7/20\n",
      "722/722 [==============================] - ETA: 0s - loss: 0.0205 - accuracy: 0.9946\n",
      "Epoch 7: saving model to best-model.hdf5\n",
      "722/722 [==============================] - 118s 163ms/step - loss: 0.0205 - accuracy: 0.9946\n",
      "Epoch 8/20\n",
      "722/722 [==============================] - ETA: 0s - loss: 0.0163 - accuracy: 0.9958\n",
      "Epoch 8: saving model to best-model.hdf5\n",
      "722/722 [==============================] - 118s 163ms/step - loss: 0.0163 - accuracy: 0.9958\n",
      "Epoch 9/20\n",
      "722/722 [==============================] - ETA: 0s - loss: 0.0190 - accuracy: 0.9951\n",
      "Epoch 9: saving model to best-model.hdf5\n",
      "722/722 [==============================] - 118s 163ms/step - loss: 0.0190 - accuracy: 0.9951\n",
      "Epoch 10/20\n",
      "722/722 [==============================] - ETA: 0s - loss: 0.0116 - accuracy: 0.9974\n",
      "Epoch 10: saving model to best-model.hdf5\n",
      "722/722 [==============================] - 118s 163ms/step - loss: 0.0116 - accuracy: 0.9974\n",
      "Epoch 11/20\n",
      "722/722 [==============================] - ETA: 0s - loss: 0.0085 - accuracy: 0.9978\n",
      "Epoch 11: saving model to best-model.hdf5\n",
      "722/722 [==============================] - 118s 163ms/step - loss: 0.0085 - accuracy: 0.9978\n",
      "Epoch 12/20\n",
      "722/722 [==============================] - ETA: 0s - loss: 0.0119 - accuracy: 0.9970\n",
      "Epoch 12: saving model to best-model.hdf5\n",
      "722/722 [==============================] - 118s 163ms/step - loss: 0.0119 - accuracy: 0.9970\n",
      "Epoch 13/20\n",
      "722/722 [==============================] - ETA: 0s - loss: 0.0056 - accuracy: 0.9983\n",
      "Epoch 13: saving model to best-model.hdf5\n",
      "722/722 [==============================] - 127s 176ms/step - loss: 0.0056 - accuracy: 0.9983\n",
      "Epoch 14/20\n",
      "722/722 [==============================] - ETA: 0s - loss: 0.0035 - accuracy: 0.9993\n",
      "Epoch 14: saving model to best-model.hdf5\n",
      "722/722 [==============================] - 129s 179ms/step - loss: 0.0035 - accuracy: 0.9993\n",
      "Epoch 15/20\n",
      "722/722 [==============================] - ETA: 0s - loss: 0.0074 - accuracy: 0.9978\n",
      "Epoch 15: saving model to best-model.hdf5\n",
      "722/722 [==============================] - 121s 168ms/step - loss: 0.0074 - accuracy: 0.9978\n",
      "Epoch 16/20\n",
      "722/722 [==============================] - ETA: 0s - loss: 0.0060 - accuracy: 0.9981\n",
      "Epoch 16: saving model to best-model.hdf5\n",
      "722/722 [==============================] - 121s 168ms/step - loss: 0.0060 - accuracy: 0.9981\n",
      "Epoch 17/20\n",
      "722/722 [==============================] - ETA: 0s - loss: 0.0026 - accuracy: 0.9995\n",
      "Epoch 17: saving model to best-model.hdf5\n",
      "722/722 [==============================] - 121s 168ms/step - loss: 0.0026 - accuracy: 0.9995\n",
      "Epoch 18/20\n",
      "722/722 [==============================] - ETA: 0s - loss: 0.0109 - accuracy: 0.9975\n",
      "Epoch 18: saving model to best-model.hdf5\n",
      "722/722 [==============================] - 122s 169ms/step - loss: 0.0109 - accuracy: 0.9975\n",
      "Epoch 19/20\n",
      "722/722 [==============================] - ETA: 0s - loss: 0.0059 - accuracy: 0.9988\n",
      "Epoch 19: saving model to best-model.hdf5\n",
      "722/722 [==============================] - 123s 170ms/step - loss: 0.0059 - accuracy: 0.9988\n",
      "Epoch 20/20\n",
      "722/722 [==============================] - ETA: 0s - loss: 0.0034 - accuracy: 0.9992\n",
      "Epoch 20: saving model to best-model.hdf5\n",
      "722/722 [==============================] - 122s 169ms/step - loss: 0.0034 - accuracy: 0.9992\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x=Xtrain, y=ytrain, batch_size=30, epochs=20, callbacks=callbacks_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d50b550d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"best-model1.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "85396e6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(7,7)) \n",
    "plt.grid() \n",
    "plt.plot(history.history['loss'])\n",
    "plt.ylabel('Loss') \n",
    "plt.xlabel('Epochs') \n",
    "plt.legend(['Training'], loc='upper right') \n",
    "plt.savefig(\"SALINAS_loss_curve.pdf\") \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c27ce309",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(7,7)) \n",
    "plt.ylim(0,1.1) \n",
    "plt.grid() \n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.ylabel('Accuracy') \n",
    "plt.xlabel('Epochs') \n",
    "plt.legend(['Training']) \n",
    "plt.savefig(\"SALINAS_acc_curve.pdf\") \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4ad5d0ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load best weights\n",
    "model.load_weights(\"best-model.hdf5\")\n",
    "model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8b17a3b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32478, 24, 24, 3, 1)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtest = Xtest.reshape(-1, windowSize, windowSize, K, 1)\n",
    "Xtest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "16609b2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32478, 16)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ytest = np_utils.to_categorical(ytest)\n",
    "ytest.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f753bae1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1015/1015 [==============================] - 19s 18ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1205\n",
      "           1       1.00      1.00      1.00      2236\n",
      "           2       1.00      1.00      1.00      1186\n",
      "           3       1.00      1.00      1.00       836\n",
      "           4       1.00      1.00      1.00      1607\n",
      "           5       1.00      1.00      1.00      2375\n",
      "           6       1.00      1.00      1.00      2147\n",
      "           7       0.91      1.00      0.95      6763\n",
      "           8       1.00      1.00      1.00      3722\n",
      "           9       1.00      1.00      1.00      1967\n",
      "          10       1.00      1.00      1.00       641\n",
      "          11       1.00      1.00      1.00      1156\n",
      "          12       1.00      1.00      1.00       550\n",
      "          13       1.00      1.00      1.00       642\n",
      "          14       1.00      0.85      0.92      4361\n",
      "          15       1.00      1.00      1.00      1084\n",
      "\n",
      "    accuracy                           0.98     32478\n",
      "   macro avg       0.99      0.99      0.99     32478\n",
      "weighted avg       0.98      0.98      0.98     32478\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Y_pred_test = model.predict(Xtest)\n",
    "y_pred_test = np.argmax(Y_pred_test, axis=1)\n",
    " \n",
    "classification = classification_report(np.argmax(ytest, axis=1), y_pred_test)\n",
    "print(classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c8e9db04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def AA_andEachClassAccuracy(confusion_matrix):\n",
    "    counter = confusion_matrix.shape[0]\n",
    "    list_diag = np.diag(confusion_matrix)\n",
    "    list_raw_sum = np.sum(confusion_matrix, axis=1)\n",
    "    each_acc = np.nan_to_num(truediv(list_diag, list_raw_sum))\n",
    "    average_acc = np.mean(each_acc)\n",
    "    return each_acc, average_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "007362c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reports (X_test,y_test,name):\n",
    "    #start = time.time()\n",
    "    Y_pred = model.predict(X_test)\n",
    "    y_pred = np.argmax(Y_pred, axis=1)\n",
    "    #end = time.time()\n",
    "    #print(end - start)\n",
    "   \n",
    "    if name == 'SA':\n",
    "        target_names = ['Brocoli_green_weeds_1','Brocoli_green_weeds_2','Fallow','Fallow_rough_plow','Fallow_smooth',\n",
    "                        'Stubble','Celery','Grapes_untrained','Soil_vinyard_develop','Corn_senesced_green_weeds',\n",
    "                        'Lettuce_romaine_4wk','Lettuce_romaine_5wk','Lettuce_romaine_6wk','Lettuce_romaine_7wk',\n",
    "                        'Vinyard_untrained','Vinyard_vertical_trellis']\n",
    "  \n",
    "    \n",
    "    classification = classification_report(np.argmax(y_test, axis=1), y_pred, target_names=target_names)\n",
    "    oa = accuracy_score(np.argmax(y_test, axis=1), y_pred)\n",
    "    confusion = confusion_matrix(np.argmax(y_test, axis=1), y_pred)\n",
    "    each_acc, aa = AA_andEachClassAccuracy(confusion)\n",
    "    kappa = cohen_kappa_score(np.argmax(y_test, axis=1), y_pred)\n",
    "    score = model.evaluate(X_test, y_test, batch_size=32)\n",
    "    Test_Loss =  score[0]*100\n",
    "    Test_accuracy = score[1]*100\n",
    "    \n",
    "    return classification, confusion, Test_Loss, Test_accuracy, oa*100, each_acc*100, aa*100, kappa*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "27d9275a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1015/1015 [==============================] - 18s 18ms/step\n",
      "1015/1015 [==============================] - 20s 18ms/step - loss: 0.0608 - accuracy: 0.9794\n"
     ]
    }
   ],
   "source": [
    "classification, confusion, Test_loss, Test_accuracy, oa, each_acc, aa, kappa = reports(Xtest,ytest,dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3d5562bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "classification = str(classification)\n",
    "confusion = str(confusion)\n",
    "file_name = \"SALINAS_classification_report.txt\"\n",
    "\n",
    "with open(file_name, 'w') as x_file:\n",
    "    x_file.write('{} Test loss (%)'.format(Test_loss))\n",
    "    x_file.write('\\n')\n",
    "    x_file.write('{} Test accuracy (%)'.format(Test_accuracy))\n",
    "    x_file.write('\\n')\n",
    "    x_file.write('\\n')\n",
    "    x_file.write('{} Kappa accuracy (%)'.format(kappa))\n",
    "    x_file.write('\\n')\n",
    "    x_file.write('{} Overall accuracy (%)'.format(oa))\n",
    "    x_file.write('\\n')\n",
    "    x_file.write('{} Average accuracy (%)'.format(aa))\n",
    "    x_file.write('\\n')\n",
    "    x_file.write('\\n')\n",
    "    x_file.write('{}'.format(classification))\n",
    "    x_file.write('\\n')\n",
    "    x_file.write('{}'.format(confusion))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "97685dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Patch(data,height_index,width_index):\n",
    "    height_slice = slice(height_index, height_index+PATCH_SIZE)\n",
    "    width_slice = slice(width_index, width_index+PATCH_SIZE)\n",
    "    patch = data[height_slice, width_slice, :]\n",
    "    \n",
    "    return patch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "0abcfd8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=loadmat('../hyperspectral/salinas_corrected.mat')['salinas_corrected']\n",
    "y=loadmat('../hyperspectral/salinas_gt.mat')['salinas_gt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "278071d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "height = y.shape[0]\n",
    "width = y.shape[1]\n",
    "PATCH_SIZE = windowSize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6d3266bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 3\n",
    "X,fa = applyFA(X, numComponents=K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "55cacb73",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = padWithZeros(X, PATCH_SIZE//2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "90436f6e",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "too many indices for array: array is 1-dimensional, but 2 were indexed",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-48-aa7351b057d0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mheight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwidth\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m         \u001b[0mtarget\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtarget\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m             \u001b[1;32mcontinue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: too many indices for array: array is 1-dimensional, but 2 were indexed"
     ]
    }
   ],
   "source": [
    "# calculate the predicted image\n",
    "outputs = np.zeros((height,width))\n",
    "for i in range(height):\n",
    "    for j in range(width):\n",
    "        target = int(y[i,j])\n",
    "        if target == 0 :\n",
    "            continue\n",
    "        else :\n",
    "            image_patch=Patch(X,i,j)\n",
    "            X_test_image = image_patch.reshape(1,image_patch.shape[0],image_patch.shape[1], image_patch.shape[2], 1).astype('float32')                                   \n",
    "            prediction = (model.predict(X_test_image))\n",
    "            prediction = np.argmax(prediction, axis=1)\n",
    "            outputs[i][j] = prediction+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1048cca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ground_truth = spectral.imshow(classes = y,figsize =(7,7))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02838f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_image = spectral.imshow(classes = outputs.astype(int),figsize =(7,7))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b446b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "spectral.save_rgb(\"SALINAS_predictions.jpg\", outputs.astype(int), colors=spectral.spy_colors)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
